prepare:
  remove_stopwords: 0
  remove_shadda: 1
  remove_tashkeel: 1
  remove_tatweel: 1
  remove_punc: 1
  normalize: 0
  remove_repeats: 0
  remove_nonarabic: 1
  stemming: 0
train:
  vocab_size: 10000
  input_length: 200
  embedding_dim: 64
  learning_rate: 0.0001
  validation_split: 0.2
  epochs: 100
  batch_size: 32
  bi_lstm_units: [64]
  dense_units: [64]
  hidden_activation: "relu"
  regularization_factor: 0.001
  dropout_factor: 0
